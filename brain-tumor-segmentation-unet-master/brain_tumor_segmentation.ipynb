{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "4EFZCuqpuWfe",
    "outputId": "cf1b034a-1487-432c-ea00-f69270a671fe"
   },
   "outputs": [],
   "source": [
    "!pip install hdf5storage\n",
    "!git clone https://github.com/adityajn105/brain-tumor-segmentation-unet\n",
    "!bash tumor-segmentation-unet/download_data.sh\n",
    "!python tumor-segmentation-unet/mat_to_numpy.py brain_tumor_dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "m453oM2Zj1BA",
    "outputId": "b1f6502d-69ca-42eb-d4e6-313f6c16b0ab"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "integer_to_class = {'1': 'meningioma (1)', '2': 'glioma (2)', '3': 'pituitary tumor (3)'}\n",
    "\n",
    "##Load images, labels, masks\n",
    "labels = np.load('brain_tumor_dataset/labels.npy')\n",
    "images = np.clip( (np.load('brain_tumor_dataset/images.npy')/12728),0,1)\n",
    "masks = np.load('brain_tumor_dataset/masks.npy')*1\n",
    "print(labels.shape)\n",
    "print(images.shape)\n",
    "print(masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "oTxNHKzPXFTK",
    "outputId": "3d2f0d27-bc80-4f13-ee76-d1695a186583"
   },
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "img_size_ori = 512\n",
    "img_size_target = 128\n",
    "\n",
    "images = np.expand_dims(images,axis=-1)\n",
    "masks = np.expand_dims(masks,axis=-1)\n",
    "\n",
    "def downsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True,)\n",
    "    \n",
    "def upsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)\n",
    "  \n",
    "images = np.array([ downsample(image) for image in images ])\n",
    "masks = (np.array([ downsample(mask) for mask in masks ])>0)*1\n",
    "\n",
    "print(images.shape)\n",
    "print(masks.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "EISjQccNpyv9",
    "outputId": "2f507cba-fc17-40a3-cf26-cf2447b1af6c"
   },
   "outputs": [],
   "source": [
    "classes, counts = np.unique(labels,return_counts=True)\n",
    "plt.bar(classes,counts,tick_label=list(integer_to_class.values()))\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "id": "c30PtaQIquAA",
    "outputId": "4c0f9c69-d054-4ba2-f88b-a70198e297ca"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "for i, idx in enumerate(np.random.randint(images.shape[0], size=18), start=1):\n",
    "    plt.subplot(3, 6, i)\n",
    "    plt.imshow( np.squeeze(images[idx],axis=-1), cmap='gray')\n",
    "    plt.imshow( np.squeeze(np.ones_like(masks[idx])-masks[idx],axis=-1), alpha=0.5, cmap='Set1')\n",
    "    plt.title(integer_to_class[str(labels[idx])])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tKAr7g_t5rgd"
   },
   "source": [
    "### Train Image and its mask which is to be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "id": "axj-fH992zom",
    "outputId": "0910e1f2-a373-4692-8eb6-6fda1e09e13f"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "i=1\n",
    "for idx in np.random.randint( images.shape[0], size=9):\n",
    "  plt.subplot(3,6,i);i+=1\n",
    "  plt.imshow( np.squeeze(images[idx],axis=-1))\n",
    "  plt.title(\"Train Image\")\n",
    "  plt.axis('off')\n",
    "  plt.subplot(3,6,i);i+=1\n",
    "  plt.imshow( np.squeeze(masks[idx],axis=-1)) \n",
    "  plt.title(\"Train Mask\")\n",
    "  plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4q1ICWtBBroq",
    "outputId": "10108f99-03d7-41db-9f75-5f6998a16656"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "X,X_v,Y,Y_v = train_test_split( images,masks,test_size=0.2,stratify=labels)\n",
    "del images\n",
    "del masks\n",
    "del labels\n",
    "gc.collect()\n",
    "X.shape,X_v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nzKAQI-V7zah"
   },
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NCHv4pjX5CSd",
    "outputId": "da94819a-e5b1-49c8-fa1b-582b993b1d91"
   },
   "outputs": [],
   "source": [
    "X = np.append( X, [ np.fliplr(x) for x in X], axis=0 )\n",
    "Y = np.append( Y, [ np.fliplr(y) for y in Y], axis=0 )\n",
    "X.shape,Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Zrf28ZDQAvjJ",
    "outputId": "63b8d0e8-f856-488c-bdb0-ab2442eea752"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(brightness_range=(0.9,1.1),\n",
    "                                   zoom_range=[.9,1.1],\n",
    "                                   fill_mode='nearest')\n",
    "val_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9acZGpnYDNw1"
   },
   "source": [
    "### Defining Dice Loss\n",
    "Dice = 2|Aâˆ©B|/|A|+|B|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7hlqTp52C6J4"
   },
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "### bce_dice_loss = binary_crossentropy_loss + dice_loss\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "IbjruP71DV9n",
    "outputId": "3ba540a5-33ae-4a43-d706-13b002874294"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, Dropout, Input, BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras.models import Model\n",
    "\n",
    "IMG_DIM = (128,128,1)\n",
    "\n",
    "def conv2d_block( input_tensor, n_filters, kernel_size = (3,3), name=\"contraction\"):\n",
    "  \"Add 2 conv layer\"\n",
    "  x = Conv2D(filters=n_filters, kernel_size=kernel_size, kernel_initializer='he_normal', \n",
    "             padding='same',activation=\"relu\", name=name+'_1')(input_tensor)\n",
    "  \n",
    "  x = Conv2D(filters=n_filters, kernel_size=kernel_size, kernel_initializer='he_normal', \n",
    "             padding='same',activation=\"relu\",name=name+'_2')(x)\n",
    "  return x\n",
    "  \n",
    "\n",
    "inp = Input( shape=IMG_DIM )\n",
    "\n",
    "d1 = conv2d_block( inp, 64, name=\"contraction_1\")\n",
    "p1 = MaxPooling2D( pool_size=(2,2), strides=(2,2))(d1)\n",
    "p1 = BatchNormalization(momentum=0.8)(p1)\n",
    "p1 = Dropout(0.1)(p1)\n",
    "\n",
    "d2 = conv2d_block( p1, 128, name=\"contraction_2_1\" )\n",
    "p2 = MaxPooling2D(pool_size=(2,2), strides=(2,2) )(d2)\n",
    "p2 = BatchNormalization(momentum=0.8)(p2)\n",
    "p2 = Dropout(0.1)(p2)\n",
    "\n",
    "d3 = conv2d_block( p2, 256, name=\"contraction_3_1\")\n",
    "p3 = MaxPooling2D(pool_size=(2,2), strides=(2,2) )(d3)\n",
    "p3 = BatchNormalization(momentum=0.8)(p3)\n",
    "p3 = Dropout(0.1)(p3)\n",
    "\n",
    "d4 = conv2d_block(p3,512, name=\"contraction_4_1\")\n",
    "p4 = MaxPooling2D(pool_size=(2,2), strides=(2,2) )(d4)\n",
    "p4 = BatchNormalization(momentum=0.8)(p4)\n",
    "p4 = Dropout(0.1)(p4)\n",
    "\n",
    "d5 = conv2d_block(p4,512, name=\"contraction_5_1\")\n",
    "\n",
    "u1 = Conv2DTranspose(512, (3, 3), strides = (2, 2), padding = 'same')(d5)\n",
    "u1 = concatenate([u1,d4])\n",
    "u1 = Dropout(0.1)(u1)\n",
    "c1 = conv2d_block(u1, 512, name=\"expansion_1\")\n",
    "\n",
    "u2 = Conv2DTranspose(256, (3, 3), strides = (2, 2), padding = 'same')(c1)\n",
    "u2 = concatenate([u2,d3])\n",
    "u2 = Dropout(0.1)(u2)\n",
    "c2 = conv2d_block(u2, 256, name=\"expansion_2\")\n",
    "\n",
    "u3 = Conv2DTranspose(128, (3, 3), strides = (2, 2), padding = 'same')(c2)\n",
    "u3 = concatenate([u3,d2])\n",
    "u3 = Dropout(0.1)(u3)\n",
    "c3 = conv2d_block(u3, 128, name=\"expansion_3\")\n",
    "\n",
    "u4 = Conv2DTranspose(64, (3, 3), strides = (2, 2), padding = 'same')(c3)\n",
    "u4 = concatenate([u4,d1])\n",
    "u4 = Dropout(0.1)(u4)\n",
    "c4 = conv2d_block(u4,64, name=\"expansion_4\")\n",
    "\n",
    "out = Conv2D(1, (1,1), name=\"output\", activation='sigmoid')(c4)\n",
    "\n",
    "unet = Model( inp, out )\n",
    "unet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fuQfiXzAMTp0"
   },
   "source": [
    "### Defining IOU metric and compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "O7RmzPp6FLiJ",
    "outputId": "f0eb6155-a73d-40e7-aa08-854524435833"
   },
   "outputs": [],
   "source": [
    "def get_iou_vector(A, B):\n",
    "    t = A>0\n",
    "    p = B>0\n",
    "    intersection = np.logical_and(t,p)\n",
    "    union = np.logical_or(t,p)\n",
    "    iou = (np.sum(intersection) + 1e-10 )/ (np.sum(union) + 1e-10)\n",
    "    return iou\n",
    "\n",
    "def iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "unet.compile(optimizer=optimizers.Adam(lr=1e-3), \n",
    "             loss=bce_dice_loss, metrics=['accuracy',iou_metric])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "llR10XboMXGI",
    "outputId": "cca57f6b-3647-4562-b851-32cb12b2959b"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import load_model\n",
    "\n",
    "model_checkpoint  = ModelCheckpoint('model_best_checkpoint.h5', save_best_only=True, \n",
    "                                    monitor='val_loss', mode='min', verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, mode='min')\n",
    "reduceLR = ReduceLROnPlateau(patience=4, verbose=2, monitor='val_loss',min_lr=1e-4, mode='min')\n",
    "\n",
    "callback_list = [early_stopping, reduceLR, model_checkpoint]\n",
    "\n",
    "train_generator = train_datagen.flow(X, Y, batch_size=32)\n",
    "val_generator = val_datagen.flow(X_v, Y_v, batch_size=32)\n",
    "\n",
    "hist = unet.fit(X,Y,batch_size=32,epochs=100,\n",
    "               validation_data=(X_v,Y_v),verbose=1,callbacks= callback_list)\n",
    "\n",
    "unet = load_model('model_best_checkpoint.h5', custom_objects={'bce_dice_loss': bce_dice_loss,'iou_metric':iou_metric}) #or compile = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "colab_type": "code",
    "id": "vBgb-raTKt2N",
    "outputId": "52348e29-77fa-474f-a33d-63f1c92e8840"
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(16, 4))\n",
    "t = f.suptitle('Unet Performance in Segmenting Tumors', fontsize=12)\n",
    "f.subplots_adjust(top=0.85, wspace=0.3)\n",
    "epoch_list = hist.epoch\n",
    "\n",
    "ax1.plot(epoch_list, hist.history['acc'], label='Train Accuracy')\n",
    "ax1.plot(epoch_list, hist.history['val_acc'], label='Validation Accuracy')\n",
    "ax1.set_xticks(np.arange(0, epoch_list[-1], 5))\n",
    "ax1.set_ylabel('Accuracy Value');ax1.set_xlabel('Epoch');ax1.set_title('Accuracy')\n",
    "ax1.legend(loc=\"best\");ax1.grid(color='gray', linestyle='-', linewidth=0.5)\n",
    "\n",
    "ax2.plot(epoch_list, hist.history['loss'], label='Train Loss')\n",
    "ax2.plot(epoch_list, hist.history['val_loss'], label='Validation Loss')\n",
    "ax2.set_xticks(np.arange(0, epoch_list[-1], 5))\n",
    "ax2.set_ylabel('Loss Value');ax2.set_xlabel('Epoch');ax2.set_title('Loss')\n",
    "ax2.legend(loc=\"best\");ax2.grid(color='gray', linestyle='-', linewidth=0.5)\n",
    "\n",
    "ax3.plot(epoch_list, hist.history['iou_metric'], label='Train IOU metric')\n",
    "ax3.plot(epoch_list, hist.history['val_iou_metric'], label='Validation IOU metric')\n",
    "ax3.set_xticks(np.arange(0, epoch_list[-1], 5))\n",
    "ax3.set_ylabel('IOU metric');ax3.set_xlabel('Epoch');ax3.set_title('IOU metric')\n",
    "ax3.legend(loc=\"best\");ax3.grid(color='gray', linestyle='-', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YRh0Q4KbnXm6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GsgHta1LjI_T"
   },
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def get_iou_vector(A, B):\n",
    "    t = A>0\n",
    "    p = B>0\n",
    "    intersection = np.logical_and(t,p)\n",
    "    union = np.logical_or(t,p)\n",
    "    iou = (np.sum(intersection) + 1e-10 )/ (np.sum(union) + 1e-10)\n",
    "    return iou\n",
    "  \n",
    "def getIOUCurve(mask_org,predicted):\n",
    "  thresholds = np.linspace(0, 1, 100)\n",
    "  ious = np.array([get_iou_vector(mask_org, predicted > threshold) for threshold in thresholds])\n",
    "  thres_best_index = np.argmax(ious[9:-10]) + 9\n",
    "  iou_best = ious[thres_best_index]\n",
    "  thres_best = thresholds[thres_best_index]\n",
    "  return thresholds,ious,iou_best,thres_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "colab_type": "code",
    "id": "VxaQOEY7jKdy",
    "outputId": "bb0f00c7-ced8-4184-b867-7e7c56adcc02"
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "t = f.suptitle('Unet Performance', fontsize=12)\n",
    "f.subplots_adjust(top=0.85, wspace=0.3)\n",
    "\n",
    "th, ious, iou_best, th_best = getIOUCurve(Y_v,unet.predict(X_v))\n",
    "ax1.plot(th, ious,label=\"For Validation\")\n",
    "ax1.plot(th_best, iou_best, \"xr\", label=\"Best threshold\")\n",
    "ax1.set_ylabel('IOU');ax1.set_xlabel('Threshold')\n",
    "ax1.set_title(\"Threshold vs IoU ({}, {})\".format(th_best, iou_best))\n",
    "\n",
    "th, ious, iou_best, th_best = getIOUCurve(Y,unet.predict(X))\n",
    "ax2.plot(th, ious, label=\"For Training\")\n",
    "ax2.plot(th_best, iou_best, \"xr\", label=\"Best threshold\")\n",
    "ax2.set_ylabel('IOU');ax1.set_xlabel('Threshold')\n",
    "ax2.set_title(\"Threshold vs IoU ({}, {})\".format(th_best, iou_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "n3-iDU-aMAtq",
    "outputId": "e3b6bac3-ff86-4269-e464-e2e141299219"
   },
   "outputs": [],
   "source": [
    "THRESHOLD = 0.2\n",
    "predicted_mask = (unet.predict(X_v)>THRESHOLD)*1\n",
    "\n",
    "plt.figure(figsize=(8,30))\n",
    "i=1;total=10\n",
    "temp = np.ones_like( Y_v[0] )\n",
    "for idx in np.random.randint(0,high=X_v.shape[0],size=total):\n",
    "    plt.subplot(total,3,i);i+=1\n",
    "    plt.imshow( np.squeeze(X_v[idx],axis=-1), cmap='gray' )\n",
    "    plt.title(\"MRI Image\");plt.axis('off')\n",
    "    \n",
    "    plt.subplot(total,3,i);i+=1\n",
    "    plt.imshow( np.squeeze(X_v[idx],axis=-1), cmap='gray' )\n",
    "    plt.imshow( np.squeeze(temp - Y_v[idx],axis=-1), alpha=0.2, cmap='Set1' )\n",
    "    plt.title(\"Original Mask\");plt.axis('off')\n",
    "    \n",
    "    plt.subplot(total,3,i);i+=1\n",
    "    plt.imshow( np.squeeze(X_v[idx],axis=-1), cmap='gray' )\n",
    "    plt.imshow( np.squeeze(temp - predicted_mask[idx],axis=-1),  alpha=0.2, cmap='Set1' )\n",
    "    plt.title(\"Predicted Mask\");plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6wo4TH2wqal6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "brain-tumor-segmentation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
